{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from blocks.bricks import Linear, Softmax, Rectifier\n",
    "from theano import tensor\n",
    "from fuel.datasets import DogsVsCats\n",
    "from fuel.schemes import ShuffledScheme, SequentialScheme\n",
    "from fuel.streams import DataStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformer import ResizeTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fuel.utils.Subset at 0x7f74a9ac5f98>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DogsVsCats(('train',), subset=slice(0, 20000))\n",
    "dataset.subsets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "astream = DataStream.default_stream(\n",
    "    dataset,\n",
    "    iteration_scheme=SequentialScheme(dataset.num_examples, 32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stream = ResizeTransformer(astream, size=(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_features': ('batch', 'channel', 'height', 'width'),\n",
       " 'targets': ('batch', 'index')}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream.axis_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "3\n",
      "28\n",
      "28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40000001"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(stream.get_epoch_iterator())\n",
    "im = data[0][0]\n",
    "print(len(data[0]))\n",
    "print(len(im))\n",
    "print(len(im[0]))\n",
    "print(len(im[0][0]))\n",
    "data[0][0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from blocks.bricks.conv import Convolutional, MaxPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FirstConvo = Convolutional(name='First Convo', filter_size=(7,7), num_filters=20, num_channels=3)\n",
    "FirstPooling = MaxPooling(name='First Pooling', pooling_size=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fuel.datasets import MNIST\n",
    "mnist = MNIST((\"train\",))\n",
    "\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import SequentialScheme\n",
    "from fuel.transformers import Flatten\n",
    "data_stream_mnist = Flatten(DataStream.default_stream(\n",
    "    mnist,     \n",
    "    iteration_scheme=SequentialScheme(mnist.num_examples, batch_size=256)))\n",
    "\n",
    "mnist_test = MNIST((\"test\",))\n",
    "data_stream_test_mnist = Flatten(DataStream.default_stream(\n",
    "     mnist_test,\n",
    "     iteration_scheme=SequentialScheme(\n",
    "         mnist_test.num_examples, batch_size=32000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = True\n",
    "if mnist:\n",
    "    ds = data_stream_mnist\n",
    "    dst = data_stream_test_mnist\n",
    "else:\n",
    "    ds = Flatten(stream)\n",
    "    mnist_test = DogsVsCats(('test',))\n",
    "    dst = Flatten(ResizeTransformer(\n",
    "        DataStream.default_stream(\n",
    "            mnist_test,\n",
    "            iteration_scheme=SequentialScheme(mnist_test.num_examples, batch_size=1024))\n",
    "                ,(28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tensor.matrix('features')\n",
    "\n",
    "from blocks.bricks import Linear, Rectifier, Softmax\n",
    "input_to_hidden = Linear(name='input_to_hidden', input_dim=784, output_dim=50)\n",
    "h = Rectifier().apply(input_to_hidden.apply(x))\n",
    "hidden_to_output = Linear(name='hidden_to_output', input_dim=50, output_dim=10)\n",
    "y_hat = Softmax().apply(hidden_to_output.apply(h))\n",
    "\n",
    "y = tensor.lmatrix('targets')\n",
    "from blocks.bricks.cost import CategoricalCrossEntropy\n",
    "cost = CategoricalCrossEntropy().apply(y.flatten(), y_hat)\n",
    "\n",
    "from blocks.roles import WEIGHT\n",
    "from blocks.graph import ComputationGraph\n",
    "from blocks.filter import VariableFilter\n",
    "cg = ComputationGraph(cost)\n",
    "W1, W2 = VariableFilter(roles=[WEIGHT])(cg.variables)\n",
    "cost = cost + 0.005 * (W1 ** 2).sum() + 0.005 * (W2 ** 2).sum()\n",
    "cost.name = 'cost_with_regularization'\n",
    "\n",
    "from blocks.initialization import IsotropicGaussian, Constant\n",
    "input_to_hidden.weights_init = hidden_to_output.weights_init = IsotropicGaussian(0.01)\n",
    "input_to_hidden.biases_init = hidden_to_output.biases_init = Constant(0)\n",
    "input_to_hidden.initialize()\n",
    "hidden_to_output.initialize()\n",
    "\n",
    "from blocks.algorithms import GradientDescent, Scale\n",
    "algorithm = GradientDescent(cost=cost, parameters=cg.parameters, step_rule=Scale(learning_rate=0.1))\n",
    "    \n",
    "from blocks.extensions.monitoring import DataStreamMonitoring\n",
    "monitor = DataStreamMonitoring(variables=[cost], data_stream=dst, prefix=\"test\")\n",
    "    \n",
    "from blocks.main_loop import MainLoop\n",
    "from blocks.extensions import FinishAfter, Printing\n",
    "main_loop = MainLoop(data_stream=ds, algorithm=algorithm,\n",
    "                     extensions=[monitor, FinishAfter(after_n_epochs=10), Printing(every_n_epochs=5, after_epoch=None)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------------------\n",
      "BEFORE FIRST EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: True\n",
      "\t epochs_done: 0\n",
      "\t iterations_done: 0\n",
      "\t received_first_batch: False\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 0:\n",
      "\t test_cost_with_regularization: 2.3221190657972564\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 5\n",
      "\t iterations_done: 1175\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 1175:\n",
      "\t test_cost_with_regularization: 0.5299817027736702\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "AFTER ANOTHER EPOCH\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 10\n",
      "\t iterations_done: 2350\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 2350:\n",
      "\t test_cost_with_regularization: 0.5123722600338344\n",
      "\t training_finish_requested: True\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "TRAINING HAS BEEN FINISHED:\n",
      "-------------------------------------------------------------------------------\n",
      "Training status:\n",
      "\t batch_interrupt_received: False\n",
      "\t epoch_interrupt_received: False\n",
      "\t epoch_started: False\n",
      "\t epochs_done: 10\n",
      "\t iterations_done: 2350\n",
      "\t received_first_batch: True\n",
      "\t resumed_from: None\n",
      "\t training_started: True\n",
      "Log records from the iteration 2350:\n",
      "\t test_cost_with_regularization: 0.5123722600338344\n",
      "\t training_finish_requested: True\n",
      "\t training_finished: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main_loop.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
